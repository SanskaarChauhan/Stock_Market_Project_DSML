{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23de3cf3-644b-4379-ab10-dfee418ed469",
   "metadata": {},
   "source": [
    "# Database (SQL Integration)\n",
    "Load enhanced data from CSV, create SQLite DB (`stock_data.db`), insert data into `stock_prices` table. Includes schema for features like Daily_Return, SMAs, and optional Volatility_20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99f4470-1c53-4f2e-9668-9ec68010b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded enhanced data: (11130, 12)\n",
      "Available columns: ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Daily Return', 'SMA_20', 'SMA_50', 'Volume Change']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "from pathlib import Path\n",
    "\n",
    "# Load enhanced CSV\n",
    "enhanced_csv = 'enhanced_stock_data.csv'\n",
    "if not Path(enhanced_csv).exists():\n",
    "    raise FileNotFoundError(f\"{enhanced_csv} not found. Run data_preprocessing_feature_engineering.ipynb first.\")\n",
    "combined_df = pd.read_csv(enhanced_csv)\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "print(f\"Loaded enhanced data: {combined_df.shape}\")\n",
    "print(f\"Available columns: {combined_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d157ee64-266c-41f5-8be1-27209dc8f7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Database 'stock_data.db' created and table 'stock_prices' ready.\n"
     ]
    }
   ],
   "source": [
    "# Create SQLite engine (file-based for persistence)\n",
    "engine = create_engine('sqlite:///stock_data.db', echo=False)  # echo=True for SQL logs if debugging\n",
    "\n",
    "# Define table schema (matching combined_df columns; includes optional Volatility_20)\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS stock_prices (\n",
    "    Date DATE,\n",
    "    Ticker TEXT,\n",
    "    Open REAL,\n",
    "    High REAL,\n",
    "    Low REAL,\n",
    "    Close REAL,\n",
    "    Adj_Close REAL,\n",
    "    Volume REAL,\n",
    "    Daily_Return REAL,\n",
    "    SMA_20 REAL,\n",
    "    SMA_50 REAL,\n",
    "    Volume_Change REAL,\n",
    "    Volatility_20 REAL  -- Optional; will be NULL if not in data\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the create table (wrapped in text() for SQLAlchemy 2.0+ compatibility)\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table_sql))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"✓ Database 'stock_data.db' created and table 'stock_prices' ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c60861a-e522-468d-89c5-eb189a871a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data insertion complete: 11130 rows inserted.\n"
     ]
    }
   ],
   "source": [
    "# Clean data for insertion (handle NaNs, rename columns for SQL compatibility)\n",
    "combined_df_clean = combined_df.copy()\n",
    "\n",
    "# Drop rows with missing core columns (Date, Ticker)\n",
    "combined_df_clean = combined_df_clean.dropna(subset=['Date', 'Ticker'])\n",
    "\n",
    "# Fill NaNs in numerical columns with 0 (or use ffill/bfill if preferred)\n",
    "numerical_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Daily Return', 'SMA_20', 'SMA_50', 'Volume Change']\n",
    "for col in numerical_cols:\n",
    "    if col in combined_df_clean.columns:\n",
    "        combined_df_clean[col] = combined_df_clean[col].fillna(0)\n",
    "\n",
    "# Add Volatility_20 if missing (set to NULL/0; compute later if needed)\n",
    "if 'Volatility_20' not in combined_df_clean.columns:\n",
    "    combined_df_clean['Volatility_20'] = 0  # Placeholder\n",
    "\n",
    "# Format Date as YYYY-MM-DD string for SQL\n",
    "combined_df_clean['Date'] = pd.to_datetime(combined_df_clean['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Rename columns (no spaces for SQL)\n",
    "combined_df_clean = combined_df_clean.rename(columns={\n",
    "    'Adj Close': 'Adj_Close',\n",
    "    'Daily Return': 'Daily_Return',\n",
    "    'Volume Change': 'Volume_Change'\n",
    "})\n",
    "\n",
    "# Reorder to match schema\n",
    "cols_order = ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Adj_Close', 'Volume', \n",
    "              'Daily_Return', 'SMA_20', 'SMA_50', 'Volume_Change', 'Volatility_20']\n",
    "combined_df_clean = combined_df_clean[cols_order]\n",
    "\n",
    "# Insert data using to_sql (handles DataFrame to SQL; 'replace' overwrites if table exists)\n",
    "combined_df_clean.to_sql('stock_prices', engine, if_exists='replace', index=False, method='multi')\n",
    "\n",
    "print(f\"✓ Data insertion complete: {len(combined_df_clean)} rows inserted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fa7320-f546-47e2-8b0e-4eb0bab931d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in table: 11130\n",
      "\n",
      "Preview of inserted data:\n",
      "         Date         Ticker         Open         High          Low  \\\n",
      "0  2022-09-26  ADANIPORTS.NS  3614.600098  3614.600098  3614.600098   \n",
      "1  2022-09-27  ADANIPORTS.NS  3614.600098  3614.600098  3614.600098   \n",
      "2  2022-09-28  ADANIPORTS.NS  3614.600098  3614.600098  3614.600098   \n",
      "3  2022-09-29  ADANIPORTS.NS  3614.600098  3614.600098  3614.600098   \n",
      "4  2022-09-30  ADANIPORTS.NS  3614.600098  3614.600098  3614.600098   \n",
      "\n",
      "         Close    Adj_Close       Volume  Daily_Return       SMA_20  \\\n",
      "0  3614.600098  3614.600098  3614.600098           0.0  3614.600098   \n",
      "1  3614.600098  3614.600098  3614.600098           0.0  3614.600098   \n",
      "2  3614.600098  3614.600098  3614.600098           0.0  3614.600098   \n",
      "3  3614.600098  3614.600098  3614.600098           0.0  3614.600098   \n",
      "4  3614.600098  3614.600098  3614.600098           0.0  3614.600098   \n",
      "\n",
      "        SMA_50  Volume_Change  Volatility_20  \n",
      "0  3614.600098            0.0              0  \n",
      "1  3614.600098            0.0              0  \n",
      "2  3614.600098            0.0              0  \n",
      "3  3614.600098            0.0              0  \n",
      "4  3614.600098            0.0              0  \n",
      "\n",
      "Rows per Ticker:\n",
      "           Ticker  Count\n",
      "0   ADANIPORTS.NS    742\n",
      "1     AXISBANK.NS    742\n",
      "2   BAJFINANCE.NS    742\n",
      "3   BHARTIARTL.NS    742\n",
      "4     HDFCBANK.NS    742\n",
      "5   HINDUNILVR.NS    742\n",
      "6    ICICIBANK.NS    742\n",
      "7         INFY.NS    742\n",
      "8          ITC.NS    742\n",
      "9           LT.NS    742\n",
      "10         M&M.NS    742\n",
      "11    RELIANCE.NS    742\n",
      "12        SBIN.NS    742\n",
      "13  TATAMOTORS.NS    742\n",
      "14         TCS.NS    742\n",
      "✓ SQL integration complete! Database ready for queries (e.g., add more cells for STDDEV fixes if needed).\n"
     ]
    }
   ],
   "source": [
    "# Verify insertion with queries\n",
    "with engine.connect() as conn:\n",
    "    # Total row count\n",
    "    row_count = conn.execute(text(\"SELECT COUNT(*) FROM stock_prices\")).scalar()\n",
    "    print(f\"Total rows in table: {row_count}\")\n",
    "    \n",
    "    # Preview first 5 rows\n",
    "    preview_sql = \"SELECT * FROM stock_prices LIMIT 5\"\n",
    "    preview_df = pd.read_sql(preview_sql, engine)\n",
    "    print(\"\\nPreview of inserted data:\")\n",
    "    print(preview_df)\n",
    "    \n",
    "    # Per-ticker count\n",
    "    ticker_count_sql = \"SELECT Ticker, COUNT(*) as Count FROM stock_prices GROUP BY Ticker\"\n",
    "    ticker_counts = pd.read_sql(ticker_count_sql, engine)\n",
    "    print(\"\\nRows per Ticker:\")\n",
    "    print(ticker_counts)\n",
    "\n",
    "print(\"✓ SQL integration complete! Database ready for queries (e.g., add more cells for STDDEV fixes if needed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a422f7e-7287-443c-af6a-7f18e2d40d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SQL Overall Summary ===\n",
      "     Avg_Close   Min_Close    Max_Close  Avg_Daily_Return   Avg_Volume  \\\n",
      "0  1854.494777  403.200012  3657.600098          0.169462  1854.494777   \n",
      "\n",
      "   Total_Records  Std_Daily_Return  \n",
      "0          11130          0.633173  \n"
     ]
    }
   ],
   "source": [
    "summary_sql = \"\"\"\n",
    "SELECT \n",
    "    AVG(Close) as Avg_Close,\n",
    "    MIN(Close) as Min_Close,\n",
    "    MAX(Close) as Max_Close,\n",
    "    AVG(Daily_Return) as Avg_Daily_Return,\n",
    "    AVG(Daily_Return * Daily_Return) as Avg_Squared_Return,\n",
    "    AVG(Volume) as Avg_Volume,\n",
    "    COUNT(*) as Total_Records\n",
    "FROM stock_prices\n",
    "WHERE Daily_Return IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "summary_df = pd.read_sql(summary_sql, engine)\n",
    "\n",
    "# Calculate std manually in Python\n",
    "summary_df['Std_Daily_Return'] = (summary_df['Avg_Squared_Return'] - summary_df['Avg_Daily_Return']**2)**0.5\n",
    "summary_df.drop(columns='Avg_Squared_Return', inplace=True)\n",
    "\n",
    "print(\"=== SQL Overall Summary ===\")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c65593-6429-48ad-873b-59c9db1260db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SQL Per-Ticker Summary ===\n",
      "           Ticker  Record_Count    Avg_Close  Avg_Return    Max_Close  \\\n",
      "0   TATAMOTORS.NS           742  3653.615933   -0.001972  3657.600098   \n",
      "1   ADANIPORTS.NS           742  3611.671526   -0.000810  3614.600098   \n",
      "2     RELIANCE.NS           742  3611.601715    2.524720  3614.600098   \n",
      "3     HDFCBANK.NS           742  3059.562706    0.004206  3062.399902   \n",
      "4         SBIN.NS           742  2519.974075    0.002520  2522.199951   \n",
      "5           LT.NS           742  1941.016528    0.000471  3657.600098   \n",
      "6    ICICIBANK.NS           742  1497.360917    0.000997  1497.500000   \n",
      "7   HINDUNILVR.NS           742  1395.820130    0.000164  2522.199951   \n",
      "8          TCS.NS           742  1392.054227    0.000533  3062.399902   \n",
      "9   BAJFINANCE.NS           742  1170.604227    0.000735  1170.800049   \n",
      "10         M&M.NS           742  1028.989353    0.004597  3614.600098   \n",
      "11        INFY.NS           742   957.928179    0.000668  1497.500000   \n",
      "12         ITC.NS           742   869.970056    0.000037   870.599976   \n",
      "13    AXISBANK.NS           742   701.982658    0.000092  1170.800049   \n",
      "14  BHARTIARTL.NS           742   405.269419    0.004965  1938.699951   \n",
      "\n",
      "      Min_Close  \n",
      "0    701.349976  \n",
      "1   1441.599976  \n",
      "2   1389.800049  \n",
      "3    957.200012  \n",
      "4    870.599976  \n",
      "5   1938.699951  \n",
      "6   1394.300049  \n",
      "7   1394.300049  \n",
      "8   1389.800049  \n",
      "9   1025.500000  \n",
      "10  1025.500000  \n",
      "11   957.200012  \n",
      "12   403.200012  \n",
      "13   701.349976  \n",
      "14   403.200012  \n"
     ]
    }
   ],
   "source": [
    "# Per-ticker summary (no STDDEV needed here)\n",
    "ticker_summary_sql = \"\"\"\n",
    "SELECT \n",
    "    Ticker,\n",
    "    COUNT(*) as Record_Count,\n",
    "    AVG(Close) as Avg_Close,\n",
    "    AVG(Daily_Return) as Avg_Return,\n",
    "    MAX(Close) as Max_Close,\n",
    "    MIN(Close) as Min_Close\n",
    "FROM stock_prices\n",
    "GROUP BY Ticker\n",
    "ORDER BY Avg_Close DESC;\n",
    "\"\"\"\n",
    "\n",
    "ticker_summary = pd.read_sql(ticker_summary_sql, engine)\n",
    "print(\"\\n=== SQL Per-Ticker Summary ===\")\n",
    "print(ticker_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ff63baa-25c3-42de-a2a5-2fc0033530ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== High Volatility Tickers ===\n",
      "Empty DataFrame\n",
      "Columns: [Ticker, Avg_Volatility]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "threshold = overall_vol_df['Avg_Vol'][0] + 1 * ((overall_vol_df['Avg_Sq_Vol'][0] - overall_vol_df['Avg_Vol'][0]**2)**0.5)\n",
    "\n",
    "high_vol_sql = f\"\"\"\n",
    "SELECT Ticker, AVG(Volatility_20) as Avg_Volatility\n",
    "FROM stock_prices\n",
    "WHERE Volatility_20 IS NOT NULL\n",
    "GROUP BY Ticker\n",
    "HAVING Avg_Volatility > {threshold}\n",
    "ORDER BY Avg_Volatility DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "high_vol = pd.read_sql(high_vol_sql, engine)\n",
    "print(\"\\n=== High Volatility Tickers ===\")\n",
    "print(high_vol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d450e9ed-f794-43c9-8615-f3691180f1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DB backed up to 'stock_data_backup.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Backup DB to CSV (for portability)\n",
    "backup_sql = \"SELECT * FROM stock_prices;\"\n",
    "backup_df = pd.read_sql(backup_sql, engine)\n",
    "backup_df.to_csv('stock_data_backup.csv', index=False)\n",
    "print(\"✓ DB backed up to 'stock_data_backup.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7755fe-4bb2-4989-9e2f-88521ebb490c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
